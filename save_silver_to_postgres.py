from pyspark.sql import SparkSession
from pyspark.sql.types import *
import os


spark = SparkSession.builder \
    .appName("LoadSilverDataToPostgres") \
    .config("spark.jars", "/home/elbahia/spark_libs/postgresql-42.6.0.jar") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

print("âœ… Spark session crÃ©Ã©e avec succÃ¨s")


jdbc_url = "jdbc:postgresql://localhost:5432/silver_data"
connection_properties = {
    "user": "silver_user",
    "password": "silver_pass123",
    "driver": "org.postgresql.Driver"
}


folder_path = "data/silver/silver_dataset_single"


df = spark.read.parquet(folder_path)

print(f"ðŸ“Š DonnÃ©es chargÃ©es: {df.count()} lignes")
df.show(5)


table_name = "silver_table"  

df.write \
    .mode("overwrite") \
    .option("batchsize", "50000") \
    .option("numPartitions", "10") \
    .jdbc(url=jdbc_url, table=table_name, properties=connection_properties)

print(f"âœ… DonnÃ©es Ã©crites dans PostgreSQL dans la table '{table_name}'")


df_read = spark.read \
    .jdbc(url=jdbc_url, table=table_name, properties=connection_properties)

print(f"ðŸ“Š Nombre de lignes dans PostgreSQL: {df_read.count()}")
df_read.show(5)

spark.stop()
print("âœ… TerminÃ© !")
